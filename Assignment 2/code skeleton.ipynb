{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f991f1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Created by Yi Zhao, IT department, Uppsala University, on 2022.9 ---------------------------------------\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e945525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FP_node: # a node in a FP tree\n",
    "    def __init__(self, name, parent):  # input: when we newly build a node in a FP tree, we know its path from 'root' (string) and the predecessor node's name (string)\n",
    "        self.name = name        #  the node's name (string, e.g. 'rootABC'), recording the path from root node to it\n",
    "        self.parent = parent    #  the name (string, e.g. 'rootAB') of the node's predecessor node  in a FP-tree\n",
    "        self.children = []      #  the names (list of strings, e.g. ['rootABCD', 'rootABCF']) of the node's successor nodes in a FP-tree\n",
    "        self.count = 0          #  the node's count (int) = the number of appearance the itemset (in original FP-tree) and can be revised (in conditional sub-FP-trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7beeebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Header_table(): # a header table\n",
    "    def __init__(self, freq_items): # input: the singleton items whose support is higher than the minimum support, sorted by their supports (list of strings)\n",
    "        self.freq_items = freq_items  # record the frequent items\n",
    "        # build an empty header table\n",
    "        self.table = {}\n",
    "        for item in freq_items:\n",
    "            self.table[item] = []\n",
    "\n",
    "    def revise_table(self, node_names): # fill the table according to a given fp-tree. Input: the names of nodes\n",
    "        for node_name in node_names:\n",
    "            if node_name != 'root':\n",
    "                self.table[node_name[-1]].append(node_name)  # node_name[-1] = the ending letter\n",
    "\n",
    "    def output_sum_counts(self, FP_tree): # compute the sum counts for all nodes with the same ending letter\n",
    "        sum_counts = {}\n",
    "        for item in self.freq_items:\n",
    "            sum_count = 0\n",
    "            for node_name in self.table[item]:\n",
    "                sum_count += FP_tree.nodes[node_name].count\n",
    "            sum_counts[item] = sum_count\n",
    "        return sum_counts   # (dictionary with string keys and int values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b70cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FP_tree:\n",
    "    def __init__(self):\n",
    "        self.nodes = {}  # the nodes the tree, (dictionary with string keys (i.e. node names) and FP-node values)\n",
    "        self.nodes['root'] = FP_node('root', None) # add the root node\n",
    "\n",
    "    def delete_unsupported_nodes(self, min_supp): # delete all the nodes that do not satisfy the minimum support\n",
    "        node_names = list(self.nodes.keys())\n",
    "        # record all the nodes that do not satisfy the minimum support\n",
    "        nodes_to_delete = []\n",
    "        for node_name in node_names:\n",
    "            if (self.nodes[node_name].count < min_supp) & (node_name != 'root'):\n",
    "                nodes_to_delete.append(node_name)\n",
    "        # revise the connection relationship before deleting nodes\n",
    "        for node_name in nodes_to_delete:\n",
    "            parent = self.nodes[node_name].parent\n",
    "            self.nodes[parent].children.remove(node_name)\n",
    "            for child in self.nodes[node_name].children:\n",
    "                if child not in nodes_to_delete:\n",
    "                    self.nodes[child].parent = parent\n",
    "        # deleting nodes\n",
    "        for node_name in nodes_to_delete:\n",
    "                self.nodes.pop(node_name)\n",
    "\n",
    "    def construct_tree_and_table(self, transactions, min_supp): # construct a FP-tree and build the corresponding header table\n",
    "        freq_items = find_frequent_items(transactions, min_supp) # the fist scan of dataset, to find the singleton items whose support is higher than the minimum support.\n",
    "        transactions = sort_and_cut_transactions(transactions, freq_items) # delete the infrequent (i.e. < min_supp) items from a transaction and sorting remaining items in descending order od supports\n",
    "        for tran in transactions:  # the second scan of dataset, tran is a row of data in transactions\n",
    "            footprint = 'root' # use footprint to record the current location in a fp-tree\n",
    "            for item in tran:\n",
    "                if footprint + item in self.nodes[footprint].children:\n",
    "                    footprint = footprint+item\n",
    "                else:\n",
    "                    self.nodes[footprint + item] = FP_node(footprint + item, footprint)  # add new node to the tree\n",
    "                    self.nodes[footprint].children.append(footprint + item)  # update the connection among nodes\n",
    "                    footprint = footprint + item  # update the current location\n",
    "                self.nodes[footprint].count += 1   # update the count\n",
    "        # accordingly build the header table\n",
    "        self.header_table = Header_table(freq_items)\n",
    "        self.header_table.revise_table(self.nodes.keys())\n",
    "\n",
    "\n",
    "    def construct_conditional_FPtree(self, suffix, min_supp): # build a fp-sub-tree with given suffix (char, e.g. 'E')\n",
    "        sub_tree = copy.deepcopy(self)  # The sub-tree is also an object belonging to Class FP-tree\n",
    "        # Step 1: build the sub-tree with given suffix\n",
    "        sub_tree.nodes = {}  #clear all the nodes\n",
    "        sub_tree.nodes['root'] = copy.deepcopy(self.nodes['root'])\n",
    "        for leaf in self.header_table.table[suffix]:\n",
    "            back_footprint = leaf  # use back_footprint to record the current location of a fp-tree when scanning\n",
    "            pre_back_footprint = []  # use pre_back_footprint to record the previous location in a fp-tree when scanning\n",
    "            # build the nodes in the sub-tree and update the count at the same time\n",
    "            while back_footprint != []:\n",
    "                if back_footprint in sub_tree.nodes.keys():\n",
    "                    sub_tree.nodes[back_footprint].count += sub_tree.nodes[pre_back_footprint].count\n",
    "                    sub_tree.nodes[back_footprint].children.append(pre_back_footprint)\n",
    "                else:\n",
    "                    sub_tree.nodes[back_footprint] = copy.deepcopy(self.nodes[back_footprint])\n",
    "                    if back_footprint in self.header_table.table[suffix]:\n",
    "                        sub_tree.nodes[back_footprint].children = []\n",
    "                    else:\n",
    "                        sub_tree.nodes[back_footprint].count = sub_tree.nodes[pre_back_footprint].count\n",
    "                        sub_tree.nodes[back_footprint].children = [pre_back_footprint]\n",
    "                if back_footprint == 'root':\n",
    "                    break\n",
    "                else:\n",
    "                    pre_back_footprint = back_footprint\n",
    "                    back_footprint = self.nodes[back_footprint].parent\n",
    "        # Step 2: deleting the nodes whose names ending with suffix\n",
    "        for node_name in self.header_table.table[suffix]:\n",
    "            parent = sub_tree.nodes[node_name].parent\n",
    "            sub_tree.nodes[parent].children.remove(node_name)\n",
    "            sub_tree.nodes.pop(node_name)\n",
    "        # Step 3: deleting the nodes that do not satisfy the minimum support\n",
    "        sub_tree.delete_unsupported_nodes(min_supp)\n",
    "        # build the corresponding header table\n",
    "        sub_tree.header_table = Header_table(self.header_table.freq_items)\n",
    "        sub_tree.header_table.revise_table(sub_tree.nodes.keys())\n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf62f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 1: import the data stored in trans1000.pkl. HINT: use function pickle.load(...)\n",
    "def import_data():\n",
    "    return transactions   #output type: list of list of char, c.f. the small dataset\n",
    "\n",
    "#TODO 2: find all the items whose supports are not less than the minimum support, and sort items in descending order of their supports\n",
    "# HINT:\n",
    "# Step 1: count and record the support of each singleton item\n",
    "#         two nesting For loops needed for scan the dataset\n",
    "#         Use a dictionary (named item_support for example) where the key is the item name (a char e.g. 'A') and the value is the support of this item (int value). Use item_support['A']=5 to record that the support of item A is 5.\n",
    "# Step 2: rule out items with support less than min_supp\n",
    "#         Use item_support.pop('A') to delete the information about item 'A' in dictionary item_support\n",
    "# Step 3: count and record the support of each singleton item\n",
    "#         Use item_support.keys() and item_support.values() to extract the keys and values in dictionary item_support, respectively\n",
    "#         Use data type conversion like np.array() and list()\n",
    "#         Use np.argsort(...) to sort the values and output the ordered indexes\n",
    "def find_frequent_items(transactions, min_supp):  #transactions: list of list of char, min_supp: int, the minimum support\n",
    "    return freq_items  # output type: list of chars\n",
    "\n",
    "\n",
    "# TODO 3: for any transaction, delete the items that are not in freq_items, and sort the remaining items with the given order of freq_items\n",
    "#  (e.g., transactions = [['A', 'C', 'D']], freq_items =['C', 'B', 'E', 'A'], then sorted_cutted_transactions= [['C', 'A']])\n",
    "#  HINT:\n",
    "#  Do steps 1&2 for all transaction:\n",
    "#         Step 1: For each item in a transaction, if it is in freq_items, record itself and its index in freq_items\n",
    "#         Step 2: For each transaction, sort the items according to the indexes recorded in Step 1\n",
    "#                 Use data type conversion like np.array() and list()\n",
    "#                 Use np.argsort(...) to sort the values and output the ordered indexes\n",
    "def sort_and_cut_transactions(transactions, freq_items):\n",
    "    return sorted_cutted_transactions  # output type: list of list of chars\n",
    "\n",
    "\n",
    "def find_frequent_itemsets(fp_tree, min_supp, post_suffix): #find the frequent itemsets with an original or conditional fp-tree, post_suffix(string): the ending part of letters that had been fixed\n",
    "    frequent_itemsets = []  # build an empty list\n",
    "    if max(fp_tree.header_table.output_sum_counts(fp_tree)) == 0: # when the fp-tree/fp-sub-tree only contains the root node\n",
    "        return []\n",
    "    else:\n",
    "        for suffix in fp_tree.header_table.freq_items: # multiple sub-problems with different ending letters\n",
    "            if fp_tree.header_table.output_sum_counts(fp_tree)[suffix] >= min_supp: # check whether the minimum support is satisfied\n",
    "                frequent_itemsets.append(suffix + post_suffix)  # record the frequent itemsets related to the current tree's leaves\n",
    "                # TODO 4: build a sub_fp_tree with suffix and min_supp\n",
    "                # TODO 5: recursively call function find_frequent_itemsets(...) to find the frequent itemsets in smaller sub-trees, and add its result frequent_itemsets. HINT: using \"sub_fp_tree, min_supp, suffix + post_suffix\" as the actual parameters, and use += to concatenate two lists\n",
    "    return frequent_itemsets  # output type: list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #------------------------------------------ Useful code for debugging --------------------------------------------------\n",
    "# #---------- A small dataset for debugging ---------------\n",
    "transactions = [\n",
    "        ['A', 'B', 'C', 'E', 'F','Z'],\n",
    "        ['A', 'C', 'G'],\n",
    "        ['A', 'C', 'D', 'E', 'G'],\n",
    "        ['A', 'C', 'E', 'G', 'L'],\n",
    "        ['A', 'C', 'B'],\n",
    "        ['A', 'B', 'D'],\n",
    "        ['A', 'B'],\n",
    "        ['A', 'B', 'K']\n",
    "        ]\n",
    "min_supp = 3\n",
    "# test function find_frequent_item\n",
    "freq_items = find_frequent_items(transactions, min_supp)\n",
    "print('freq_items:', freq_items)\n",
    "# test function sort_and_cut_transactions\n",
    "transactions = sort_and_cut_transactions(transactions, freq_items)\n",
    "print('transactions:', transactions)\n",
    "# # test function import_data\n",
    "# transactions = import_data()\n",
    "# print('transactions:',transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- The main process ----------------------------------------------------\n",
    "#-----------------------------------   Step 1: Import the dataset and parameter ------------------------------------\n",
    "# transactions = import_data()\n",
    "# min_supp = 300\n",
    "# print(transactions)\n",
    "# #-----------------------------------------   Step 2: Build a FP-growth tree -----------------------------------------\n",
    "fp_tree = FP_tree()\n",
    "fp_tree.construct_tree_and_table(transactions, min_supp)\n",
    "# #-----------------------------------------   Step 3: Find the frequent itemsets -------------------------------------\n",
    "frequent_itemsets = find_frequent_itemsets(fp_tree, min_supp, '')\n",
    "print('frequent_itemsets:', frequent_itemsets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "374px",
    "left": "656px",
    "right": "20px",
    "top": "163px",
    "width": "325px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "97a8f87bbbc030fa587d84ca543acba2559f1ef87cf41c6709592ea5fd23195a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
