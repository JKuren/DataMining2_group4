{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "8c5a8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "\n",
    "# Import os to utilize the built in functionality like the current working directory\n",
    "import os\n",
    "# For calculations\n",
    "import numpy as np\n",
    "# Import pandas to utilize dataframes and to read the xlsx files\n",
    "import pandas as pd\n",
    "# For pathnames\n",
    "import glob\n",
    "#For unlisting\n",
    "import itertools\n",
    "#For using math function like sqrt\n",
    "import math \n",
    "# Find out the current working directory\n",
    "#os.getcwd()\n",
    "#os.chdir('/Users/muhkas/Desktop/MK/') #use to set the path to working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "13f18841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self):\n",
    "        unique_processed_links= [] \n",
    "        \n",
    "    def loadfile(self, file_path):\n",
    "        \"\"\"Read the file and load the data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "         file_path: str\n",
    "            A valid file path and file name contianing the data.\n",
    "            Returns\n",
    "        -------\n",
    "        Panda Series\n",
    "            It returns Link column of the file\n",
    "\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        #TODO: Load/read the files and data\n",
    "        return(df['Link'])\n",
    "\n",
    "    \n",
    "    def removeselflinks(self, file_path):\n",
    "        \"\"\"Remove the self links and extracts only the outlinks.\n",
    "           The links are preprocessed to short name eg. https://www.uu.se/contact \n",
    "           will be converted to uu.se. \n",
    "           A web page can outlink to another page more than once, so duplicates will\n",
    "           be removed.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "         file_path: path and name of file to be read\n",
    "            \n",
    "       \n",
    "        \"\"\"\n",
    "        #TODO: Call tje laodfile and store retrun values in a variable raw_data\n",
    "        raw_data = Preprocess.loadfile(self, file_path)\n",
    "        unique_raw_data = []  \n",
    "        for i in raw_data:\n",
    "            if i.find('wikipedia.org')== -1:  #Check if a link is selflink: Files were generated from\n",
    "                                          #wikipedia, therefore a link contianing 'wikipedia.org'\n",
    "                                          #represents the inlink and is removed.\n",
    "                if i.find('/', 8)!=1:  # Check if outlink has long (e-g:https://www.uu.se/contact ) \n",
    "                                   # or short (https://www.uu.se) format\n",
    "                    intermediate_name=i[0: i.find('/', 8)]\n",
    "                else:\n",
    "                    intermediate_name=i\n",
    "             \n",
    "                if intermediate_name.find('https://')==0:\n",
    "                    intermediate_name = intermediate_name[8:]\n",
    "                elif intermediate_name.find('http://')==0:\n",
    "                    intermediate_name = intermediate_name[7:]\n",
    "                else:\n",
    "                    print('error')\n",
    "        \n",
    "                if intermediate_name.find('www.')==0:\n",
    "                    intermediate_name = intermediate_name[4:]\n",
    "                \n",
    "                if intermediate_name != [] or intermediate_name!=None: \n",
    "                    unique_raw_data.append(intermediate_name)\n",
    "\n",
    "        unique_raw_data = list(dict.fromkeys(unique_raw_data))\n",
    "        self.unique_processed_links = unique_raw_data\n",
    "                #TODO:Remove http:// or https:// etc. and store result in the in variable intermediate_name \n",
    "                \n",
    "                #TODO: #Some addresses are without www. To, keep the same format, www is removed\n",
    "                #      and store result in the variable intermediate_name\n",
    "                \n",
    "                #TODO: #Remove the empty link, if any. \n",
    "                #      and append the result in the variable unique_raw_data already defined above for loop.\n",
    "                \n",
    "                 \n",
    "                #TODO: Remove duplicates from variable unique_raw_data and update self.unique_processed_links\n",
    "                \n",
    "                \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "a9da355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopulateDictionaries(Preprocess):\n",
    "        def __init__(self):\n",
    "            self.pages={} # Create a dictionary of pages\n",
    "            self.pageindex=0 #To keep track of index of the page\n",
    "            self.inlink_dict={} #a dictionary that record in_links with pagename, pageindex, mainpageindex (page where link originated), and update mainpage indeces, if it was inlinked from more than one pages \n",
    "            self.outlink_dict={} #a dictionary that record out_links with pagename, pageindex, outlinkindex (page where link is directed to), and update mainpage indeces, if it was out bound from more than one pages \n",
    "            Preprocess.__init__(self)\n",
    "        \n",
    "        def addpages(self, list_pages):\n",
    "            \n",
    "            \"\"\"Add pages to a global dictionary of pages and index them \n",
    "       \n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "             list_pages: list\n",
    "                A processed list of all pages in a data file\n",
    "        \n",
    "            \"\"\"\n",
    "            #TODO: Add unique pages and their index in the dictionary pages\n",
    "            for i,page in enumerate(list_pages):\n",
    "                if page in self.pages:\n",
    "                    continue\n",
    "                else:    \n",
    "                    self.pages[page] = [len(self.pages)]\n",
    "            \n",
    "        def inlinkgraph(self, out_links):\n",
    "    \n",
    "            \"\"\"Creates dictionary of inlink graph that records in_links with pagename, pageindex and mainpageindex,\n",
    "                If a webpage is inlinked from more than one main pages then indeces are updated.\n",
    "                For example: Consider a entery in link_dict is  'usnews.com': [[10], [1], [44]], \n",
    "                Then, webpage usnews.com has index 10 and inlinked by main pages 1 and 44.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "             out_links: list\n",
    "                A processed list of all pages in a data file\n",
    "        \n",
    "          \n",
    "            \"\"\"\n",
    "            #print(self.pages)\n",
    "                   #TODO: Create inlink dictionary by populating self.inlink_dict see the function description:\n",
    "                   #If a webpage is inlinked from more than one main pages then indeces are updated.\n",
    "                   #For example: Consider a entery in link_dict is  'usnews.com': [[10], [1], [44]], \n",
    "                   #Then, webpage usnews.com has index 10 and inlinked by main pages 1 and 44.\n",
    "            for ind, pname in enumerate(out_links):\n",
    "                #Check if a page already exists in link_dict\n",
    "                if ind == 0:\n",
    "                    cur_pname = pname\n",
    "                if self.inlink_dict.get(pname)==None: # If a page is not present is dict\n",
    "                    self.inlink_dict[pname]= [self.pages[pname]] # Add the page and indeces\n",
    "                else: #A page already exists in the inlink_dict, update the main page indeces\n",
    "                    self.inlink_dict[pname].append(self.pages[cur_pname])\n",
    "            \n",
    "\n",
    "        def outlinkgraph(self, out_links):\n",
    "            \"\"\"Creates dictionary of out link graph that records out_links with pagename, pageindex and mainpageindex,\n",
    "                If a webpage has many out linkes then indeces are updated.\n",
    "                For example: Consider a entery in outlink_dict is  'abc.com': [[2], [5], [6]], \n",
    "                Then, webpage abc.com has index 2 and outlinked to  pages 5 and 6.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                 out_links: list\n",
    "                    A processed list of all pages in a data file\n",
    "                \n",
    "            \"\"\"\n",
    "            for ind, pname in enumerate(out_links):\n",
    "                #TODO: Create outlink dictionary by populating self.outlink_dict see the function description:\n",
    "                #For example: Consider a entery in outlink_dict is  'abc.com': [[2], [5], [6]], \n",
    "                #Then, webpage abc.com has index 2 and outlinked to  pages 5 and 6.\n",
    "                pindex = self.pages[pname]\n",
    "                if ind == 0:\n",
    "                    self.outlink_dict[pname] = [pindex]\n",
    "                    cur_pagename = pname\n",
    "                else:\n",
    "                    self.outlink_dict[cur_pagename].append(pindex)\n",
    "            #print(f'Current pagename: {cur_pagename}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "bc6dd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrices(PopulateDictionaries):\n",
    "    def __init__(self):\n",
    "        self.adj_m_pagerank=None #Initialise the adjacancey matrix for pagerank algo.\n",
    "        self.adj_m_HITS=None    #Initialise the adjacancey matrix for HITS algo.\n",
    "        PopulateDictionaries.__init__(self) \n",
    "    \n",
    "###############Create Adjacency matrix Page rank\n",
    "    def adjpagerank(self, dict_inlinks):\n",
    "        \"\"\"Adjacacy matrix for page rank algo:  \n",
    "                        #An Adjacency matrix of in links of web pages divided by total number of out links of a page.\n",
    "                        #Each element of A that is A_i,j  represents the out link from web page 'i' (row) to web page 'j' (column).\n",
    "                        #Alternatively,  We can also say that in link from web page 'j' (column) to web page 'i' (row).\n",
    "                        #Note that  for all 'i' sum(i, M_i,j) = 1 and A must be a square matrix.\n",
    "          \n",
    "        Parameters\n",
    "        ----------\n",
    "        dict_inlinks : dictionary\n",
    "               A dictionary of in links\n",
    "        \"\"\"\n",
    "        zero_data = np.zeros(shape=(len(dict_inlinks),len(dict_inlinks)))\n",
    "        self.adj_m_pagerank = pd.DataFrame(zero_data)\n",
    "        for i in dict_inlinks:\n",
    "            link_map=(list(itertools.chain(*dict_inlinks[i])))\n",
    "            for ind, j in enumerate(link_map):\n",
    "                if ind!=0: # It is the page index, but we need both the page index and main page index.\n",
    "                    #If a page index and main page index is similar then it is self link and is removed.\n",
    "                    if link_map[ind]!=link_map[0]:\n",
    "                        self.adj_m_pagerank.iat[ link_map[ind]-1, (link_map[0]-1) ]=1\n",
    "        ###########divide the 1 by the total out links (# Only divide if row sum is not 0)\n",
    "        self.adj_m_pagerank=self.adj_m_pagerank.apply(lambda x : x.div(x.sum()) if (x.sum()!=0) else 0 , axis=1) \n",
    "\n",
    "###############Create Adjacency matrix FOR HITS\n",
    "    def adjHITS(self, dict_outlinks):\n",
    "        \"\"\"Adjacacy matrix for HITS algo:  \n",
    "                        #An Adjacency matrix of out links of web pages.\n",
    "                        #Each element of L that is L_i,j  represents the out link from web page 'i' (row) to web page 'j' (column).\n",
    "                        #Note L must be a square matrix.\n",
    "                        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dict_inlinks : dictionary\n",
    "               A dictionary of out links  \n",
    "        \"\"\"\n",
    "        zero_data = np.zeros(shape=(len(dict_outlinks),len(dict_outlinks)))\n",
    "        self.adj_m_HITS = pd.DataFrame(zero_data)\n",
    "             #TODO:Populate self.adj_m_HITS as per instructions in the assignment lecture and slides \n",
    "        for i in dict_outlinks:\n",
    "            link_map=(list(itertools.chain(*dict_outlinks[i])))\n",
    "            for ind, j in enumerate(link_map):\n",
    "                if ind!=0: # It is the page index, but we need both the page index and main page index.\n",
    "                    #If a page index and main page index is similar then it is self link and is removed.\n",
    "                    if link_map[ind]!=link_map[0]:\n",
    "                        self.adj_m_HITS.iat[ link_map[ind]-1, (link_map[0]-1) ]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "e97ecf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PagerankAlgo():\n",
    "    def __init__(self, A, d):\n",
    "        self.d= d       #Teleporting parameter\n",
    "        \n",
    "        self.A= A       #An Adjacency matrix of in links of web pages divided by total number of out links of a page.\n",
    "                        #Each element of A that is A_i,j  represents the out link from web page 'i' (row) to web page 'j' (column).\n",
    "                        #Note that  for all 'i' sum(i, M_i,j) = 1 and A must be a square matrix.\n",
    "        \n",
    "        self.P= np.ones(len(self.A)) #Intial page rank =1\n",
    "\n",
    "    def calc_pagerank(self, max_itrs):\n",
    "        \"\"\"PageRank Algorithm:  This algorithm was propsed by the Larry Page and Sergey Brin at Stanford University \n",
    "                            and it ranks the web pages by measuring their importance.\n",
    "                            It is used by the search engine Google.\n",
    "                            \n",
    "        Parameters\n",
    "        ----------\n",
    "        max_itrs : int\n",
    "               Max number of iterations\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        numpy array\n",
    "            A vector of ranks such that p_i is the i-th rank in the range of [0, 1].\n",
    "    \n",
    "        Note\n",
    "        -----\n",
    "            1) Don't forget to normalize the page rank values in each iteration by max of page rank value.\n",
    "               This is done to restrict the page rank values in the range of 1-0.\n",
    "            2) Finally, normalize the page ranks by the sum of values of page ranks. This is only done at the \n",
    "               final calculation.\n",
    "               This is done to so that sum of final page ranks =1.\n",
    "        \"\"\"\n",
    "        #Check if A is square matrix\n",
    "        assert(self.A.shape[0]==self.A.shape[1])\n",
    "        page_ranks=None\n",
    "        #TODO: Implement PageRank algorithm according to assignment lecture and slides. \n",
    "        n = len(self.A)\n",
    "        for i,j in self.A:\n",
    "            for i in range(0,max_itrs):\n",
    "                self.A[i,0:len(self.A)] = (1-self.d) + self.d*self.A[i,0:len(self.A)]\n",
    "                A_t = self.A.transpose()\n",
    "                y = A_t @ self.P\n",
    "                P_hat = y/max(y)\n",
    "                page_ranks += P_hat\n",
    "\n",
    "        page_ranks = P_hat/sum(P_hat)\n",
    "            \n",
    "        return(page_ranks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "03e264ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HITSalgo():\n",
    "    def __init__(self, L):\n",
    "        self.L= L   #An Adjacency matrix of out links of web pages \n",
    "                    #Each element of L that is L_i,j  represents the out link from web page 'i' to web page 'j'.\n",
    "                    #Note that L must be a square matrix.\n",
    "                    \n",
    "        self.a= np.ones(len(L)) #Initial authority values =1\n",
    "        self.h= np.ones(len(L)) #Initial hub values =1\n",
    "\n",
    "\n",
    "\n",
    "    def calc_HITS(self, max_itrs):\n",
    "        \"\"\"HITS Algorithm:  HITS algorithm was propsed by Jon M. Lleinberg  at Cornell University \n",
    "                            and it ranks the web pages by measuring their authoraty and hubs.\n",
    "                            It is used by the search engine Ask.\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_itrs : int\n",
    "               Max number of iterations\n",
    "    \n",
    "   \n",
    "        Returns\n",
    "        -------\n",
    "        Panda series\n",
    "            A series conisting of normalized authority and  hub scores.\n",
    "    \n",
    "        Note\n",
    "        -----\n",
    "        1) Don't forget to normalize the authority score by the sum of sequare values of all authority score. \n",
    "        2) Don't forget to normalize the hub score by the sum of sequare values of all hub score.\n",
    "        \"\"\"\n",
    "       \n",
    "        #Check if adjacency matrix is a square matrix\n",
    "        assert(self.L.shape[0]==self.L.shape[1])\n",
    "        \n",
    "        a_cal=self.a\n",
    "        h_cal=self.h\n",
    "        \n",
    "        #TODO: Implement HITS algorithm according to assignment lecture and slides.\n",
    "        \n",
    "        return(a_cal, h_cal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "335c7eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "PageRankAdjMatr \n",
      "           0         1         2         3         4         5         6    \\\n",
      "0    0.000000  0.000000  0.021739  0.021739  0.000000  0.021739  0.021739   \n",
      "1    0.000000  0.000000  0.018182  0.000000  0.000000  0.000000  0.000000   \n",
      "2    0.021277  0.021277  0.000000  0.000000  0.000000  0.021277  0.000000   \n",
      "3    0.029412  0.000000  0.029412  0.000000  0.000000  0.000000  0.000000   \n",
      "4    0.000000  0.000000  0.000000  0.000000  0.000000  0.037037  0.037037   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "129  0.000000  0.027027  0.027027  0.000000  0.027027  0.027027  0.000000   \n",
      "130  0.000000  0.033333  0.033333  0.000000  0.000000  0.000000  0.000000   \n",
      "131  0.000000  0.000000  0.022727  0.000000  0.000000  0.000000  0.000000   \n",
      "132  0.000000  0.000000  0.071429  0.000000  0.000000  0.000000  0.000000   \n",
      "133  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "          7         8         9    ...       124       125       126  \\\n",
      "0    0.021739  0.021739  0.000000  ...  0.021739  0.000000  0.021739   \n",
      "1    0.018182  0.000000  0.000000  ...  0.000000  0.018182  0.018182   \n",
      "2    0.021277  0.000000  0.021277  ...  0.021277  0.000000  0.000000   \n",
      "3    0.029412  0.000000  0.029412  ...  0.000000  0.000000  0.000000   \n",
      "4    0.037037  0.000000  0.000000  ...  0.000000  0.037037  0.000000   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "129  0.027027  0.027027  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "130  0.033333  0.033333  0.000000  ...  0.033333  0.000000  0.000000   \n",
      "131  0.022727  0.022727  0.022727  ...  0.000000  0.000000  0.000000   \n",
      "132  0.071429  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "133  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
      "\n",
      "          127       128       129       130       131       132       133  \n",
      "0    0.021739  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "1    0.000000  0.000000  0.018182  0.000000  0.000000  0.000000  0.018182  \n",
      "2    0.021277  0.000000  0.000000  0.021277  0.000000  0.000000  0.000000  \n",
      "3    0.000000  0.029412  0.000000  0.000000  0.029412  0.029412  0.029412  \n",
      "4    0.000000  0.037037  0.037037  0.000000  0.000000  0.000000  0.000000  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "129  0.027027  0.027027  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "130  0.000000  0.033333  0.000000  0.000000  0.033333  0.000000  0.033333  \n",
      "131  0.022727  0.000000  0.000000  0.000000  0.000000  0.022727  0.000000  \n",
      "132  0.000000  0.071429  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "133  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[134 rows x 134 columns]\n",
      "If the rows are summing up to one in  adj_m_pagerank:\n",
      " 0     1.0\n",
      "1     1.0\n",
      "2     1.0\n",
      "3     1.0\n",
      "4     1.0\n",
      "5     1.0\n",
      "6     1.0\n",
      "7     1.0\n",
      "8     1.0\n",
      "9     1.0\n",
      "10    1.0\n",
      "11    1.0\n",
      "12    1.0\n",
      "13    1.0\n",
      "14    1.0\n",
      "15    1.0\n",
      "16    1.0\n",
      "17    1.0\n",
      "18    1.0\n",
      "19    1.0\n",
      "20    1.0\n",
      "21    1.0\n",
      "22    1.0\n",
      "23    1.0\n",
      "24    1.0\n",
      "dtype: float64\n",
      "Number of in-links in adj_m_pagerank: \n",
      " [ 26  42 104  28  24  25  50 122  50  45  45  49  44  41  26  49  40  24\n",
      "  28  12  42 113  48  44  29]\n",
      "Number of out-links in adj_m_pagerank: \n",
      " [46 55 47 34 27 20 58  9 45 57  8 59 19 55 18 13 18  3 72 20 56 15 43 48\n",
      " 56]\n",
      "HITSAdjMatr \n",
      "      0    1    2    3    4    5    6    7    8    9    ...  124  125  126  \\\n",
      "0    0.0  0.0  1.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  1.0  0.0   \n",
      "2    1.0  1.0  0.0  1.0  0.0  1.0  1.0  0.0  1.0  1.0  ...  1.0  1.0  0.0   \n",
      "3    1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  1.0  1.0   \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "129  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  1.0  0.0   \n",
      "130  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0   \n",
      "131  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  1.0  0.0   \n",
      "132  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  0.0  0.0   \n",
      "133  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  1.0  1.0  ...  0.0  1.0  1.0   \n",
      "\n",
      "     127  128  129  130  131  132  133  \n",
      "0    0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "1    0.0  1.0  1.0  1.0  0.0  0.0  1.0  \n",
      "2    1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
      "3    0.0  1.0  0.0  0.0  0.0  0.0  1.0  \n",
      "4    0.0  1.0  1.0  0.0  0.0  0.0  1.0  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  \n",
      "129  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "130  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "131  0.0  1.0  0.0  1.0  0.0  0.0  0.0  \n",
      "132  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
      "133  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
      "\n",
      "[134 rows x 134 columns]\n",
      "Number of outlinks in adj_m_HITS:\n",
      " 0      27.0\n",
      "1      43.0\n",
      "2     105.0\n",
      "3      29.0\n",
      "4      25.0\n",
      "5      26.0\n",
      "6      51.0\n",
      "7     123.0\n",
      "8      51.0\n",
      "9      46.0\n",
      "10     46.0\n",
      "11     50.0\n",
      "12     45.0\n",
      "13     42.0\n",
      "14     27.0\n",
      "15     50.0\n",
      "16     41.0\n",
      "17     24.0\n",
      "18     29.0\n",
      "19     13.0\n",
      "20     43.0\n",
      "21    114.0\n",
      "22     49.0\n",
      "23     45.0\n",
      "24     30.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#MAIN of the code, #if __name__ == '__main__'\n",
    "pp_data = AdjacencyMatrices()\n",
    "\n",
    "file_list =  glob.glob('Data_files' + \"/*.csv\")\n",
    "\n",
    "for fl in file_list:\n",
    "    pp_data.removeselflinks(fl)\n",
    "    list_out_links= list(pp_data.unique_processed_links)\n",
    "    pp_data.addpages(list_out_links)\n",
    "    pp_data.inlinkgraph(list_out_links)\n",
    "    pp_data.outlinkgraph(list_out_links)\n",
    "    pp_data.pageindex += 1\n",
    "\n",
    "#print(pp_data.pages)\n",
    "#print('In Links: \\n', pp_data.inlink_dict)\n",
    "#print('Out Links:\\n', pp_data.outlink_dict ) \n",
    "print(' \\n')\n",
    "\n",
    "#AdjacencyMatrices\n",
    "##.  PageRank\n",
    "pp_data.adjpagerank(pp_data.inlink_dict)\n",
    "print(\"PageRankAdjMatr \\n\", pp_data.adj_m_pagerank )\n",
    "print( 'If the rows are summing up to one in  adj_m_pagerank:\\n',pp_data.adj_m_pagerank.sum(axis=1)[0:25])\n",
    "print( 'Number of in-links in adj_m_pagerank: \\n',np.count_nonzero(pp_data.adj_m_pagerank, axis=0)[0:25])\n",
    "print( 'Number of out-links in adj_m_pagerank: \\n',np.count_nonzero(pp_data.adj_m_pagerank, axis=1)[0:25])\n",
    "\n",
    "##. HITS\n",
    "pp_data.adjHITS(pp_data.outlink_dict)\n",
    "print(\"HITSAdjMatr \\n\", pp_data.adj_m_HITS )\n",
    "# Number of outlinks in adj_m_HITS\n",
    "print( 'Number of outlinks in adj_m_HITS:\\n',pp_data.adj_m_HITS.sum(axis=1)[0:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "b8e75ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [607], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pr\u001b[38;5;241m=\u001b[39m PagerankAlgo(pp_data\u001b[38;5;241m.\u001b[39madj_m_pagerank , \u001b[38;5;241m0.85\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m page_rank_score\u001b[38;5;241m=\u001b[39m\u001b[43mpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalc_pagerank\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHighest page rank score is:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mmax\u001b[39m(page_rank_score))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPage rank scores:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, page_rank_score)\n",
      "Cell \u001b[1;32mIn [604], line 44\u001b[0m, in \u001b[0;36mPagerankAlgo.calc_pagerank\u001b[1;34m(self, max_itrs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     y \u001b[38;5;241m=\u001b[39m A_t \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP\n\u001b[0;32m     43\u001b[0m     P_hat \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(y)\n\u001b[1;32m---> 44\u001b[0m     page_ranks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m P_hat\n\u001b[0;32m     46\u001b[0m page_ranks \u001b[38;5;241m=\u001b[39m P_hat\u001b[38;5;241m/\u001b[39m\u001b[38;5;28msum\u001b[39m(P_hat)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(page_ranks)\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\ops\\common.py:70\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     68\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\arraylike.py:104\u001b[0m, in \u001b[0;36mOpsMixin.__radd__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__radd__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__radd__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mradd)\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\series.py:5639\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5637\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_arith_method\u001b[39m(\u001b[39mself\u001b[39m, other, op):\n\u001b[0;32m   5638\u001b[0m     \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39malign_method_SERIES(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m-> 5639\u001b[0m     \u001b[39mreturn\u001b[39;00m base\u001b[39m.\u001b[39;49mIndexOpsMixin\u001b[39m.\u001b[39;49m_arith_method(\u001b[39mself\u001b[39;49m, other, op)\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\base.py:1295\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1292\u001b[0m rvalues \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1294\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1295\u001b[0m     result \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1297\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(result, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:222\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     \u001b[39m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[1;32m--> 222\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)\n\u001b[0;32m    224\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:163\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    160\u001b[0m     func \u001b[39m=\u001b[39m partial(expressions\u001b[39m.\u001b[39mevaluate, op)\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (is_object_dtype(left\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    166\u001b[0m         \u001b[39m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    169\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m op_str \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:69\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     68\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 69\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "File \u001b[1;32mc:\\Users\\phili\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\roperator.py:9\u001b[0m, in \u001b[0;36mradd\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mradd\u001b[39m(left, right):\n\u001b[1;32m----> 9\u001b[0m     \u001b[39mreturn\u001b[39;00m right \u001b[39m+\u001b[39;49m left\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "pr= PagerankAlgo(pp_data.adj_m_pagerank , 0.85)\n",
    "page_rank_score=pr.calc_pagerank(50)\n",
    "print('Highest page rank score is:', max(page_rank_score))\n",
    "print('Page rank scores:\\n', page_rank_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca0d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest authority score: 1.0\n",
      "Authority scores:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Highest hub: 1.0\n",
      "Hub scores:\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "hr= HITSalgo(pp_data.adj_m_HITS )\n",
    "HITS_scores=hr.calc_HITS(5)\n",
    "print('Highest authority score:', max( HITS_scores[0] ))\n",
    "print('Authority scores:\\n',  HITS_scores[0] )\n",
    "\n",
    "print('Highest hub:', max( HITS_scores[1]))\n",
    "print('Hub scores:\\n',  HITS_scores[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261c092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1cf13c2935eefaf1661c08fa0a4535e671f54a605f75ab91b11f9d9e114986c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
