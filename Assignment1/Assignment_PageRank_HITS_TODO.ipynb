{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5a8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "\n",
    "# Import os to utilize the built in functionality like the current working directory\n",
    "import os\n",
    "# For calculations\n",
    "import numpy as np\n",
    "# Import pandas to utilize dataframes and to read the xlsx files\n",
    "import pandas as pd\n",
    "# For pathnames\n",
    "import glob\n",
    "#For unlisting\n",
    "import itertools\n",
    "#For using math function like sqrt\n",
    "import math \n",
    "# Find out the current working directory\n",
    "#os.getcwd()\n",
    "#os.chdir('/Users/muhkas/Desktop/MK/') #use to set the path to working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f18841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "    def __init__(self):\n",
    "        unique_processed_links= [] \n",
    "        \n",
    "    def loadfile(self, file_path):\n",
    "        \"\"\"Read the file and load the data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "         file_path: str\n",
    "            A valid file path and file name contianing the data.\n",
    "            Returns\n",
    "        -------\n",
    "        Panda Series\n",
    "            It returns Link column of the file\n",
    "\n",
    "        \"\"\"\n",
    "        #TODO: Load/read the files and data\n",
    "        return(df['Link'])\n",
    "\n",
    "    \n",
    "    def removeselflinks(self, file_path):\n",
    "        \"\"\"Remove the self links and extracts only the outlinks.\n",
    "           The links are preprocessed to short name eg. https://www.uu.se/contact \n",
    "           will be converted to uu.se. \n",
    "           A web page can outlink to another page more than once, so duplicates will\n",
    "           be removed.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "         file_path: path and name of file to be read\n",
    "            \n",
    "       \n",
    "        \"\"\"\n",
    "        #TODO: Call tje laodfile and store retrun values in a variable raw_data\n",
    "        \n",
    "        unique_raw_data = []  \n",
    "        for i in raw_data:\n",
    "            if i.find('wikipedia.org')== -1:  #Check if a link is selflink: Files were generated from\n",
    "                                          #wikipedia, therefore a link contianing 'wikipedia.org'\n",
    "                                          #represents the inlink and is removed.\n",
    "                if i.find('/', 8)!=1:  # Check if outlink has long (e-g:https://www.uu.se/contact ) \n",
    "                                   # or short (https://www.uu.se) format\n",
    "                    intermediate_name=i[0: i.find('/', 8)]\n",
    "                else:\n",
    "                    intermediate_name=i\n",
    "             \n",
    "                \n",
    "                #TODO:Remove http:// or https:// etc. and store result in the in variable intermediate_name \n",
    "                \n",
    "                #TODO: #Some addresses are without www. To, keep the same format, www is removed\n",
    "                #      and store result in the variable intermediate_name\n",
    "                \n",
    "                #TODO: #Remove the empty link, if any. \n",
    "                #      and append the result in the variable unique_raw_data already defined above for loop.\n",
    "                \n",
    "                 \n",
    "                #TODO: Remove duplicates from variable unique_raw_data and update self.unique_processed_links\n",
    "                \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9da355a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-473296c004d2>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-473296c004d2>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    def outlinkgraph(self, out_links):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class PopulateDictionaries(Preprocess):\n",
    "        def __init__(self):\n",
    "            self.pages={} # Create a dictionary of pages\n",
    "            self.pageindex=0 #To keep track of index of the page\n",
    "            self.inlink_dict={} #a dictionary that record in_links with pagename, pageindex, mainpageindex (page where link originated), and update mainpage indeces, if it was inlinked from more than one pages \n",
    "            self.outlink_dict={} #a dictionary that record out_links with pagename, pageindex, outlinkindex (page where link is directed to), and update mainpage indeces, if it was out bound from more than one pages \n",
    "            Preprocess.__init__(self)\n",
    "        \n",
    "        def addpages(self, list_pages):\n",
    "            \n",
    "            \"\"\"Add pages to a global dictionary of pages and index them \n",
    "       \n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "             list_pages: list\n",
    "                A processed list of all pages in a data file\n",
    "        \n",
    "            \"\"\"\n",
    "            #TODO: Add unique pages and their index in the dictionary pages\n",
    "            \n",
    "            \n",
    "        def inlinkgraph(self, out_links):\n",
    "    \n",
    "            \"\"\"Creates dictionary of inlink graph that records in_links with pagename, pageindex and mainpageindex,\n",
    "                If a webpage is inlinked from more than one main pages then indeces are updated.\n",
    "                For example: Consider a entery in link_dict is  'usnews.com': [[10], [1], [44]], \n",
    "                Then, webpage usnews.com has index 10 and inlinked by main pages 1 and 44.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "             out_links: list\n",
    "                A processed list of all pages in a data file\n",
    "        \n",
    "          \n",
    "            \"\"\"\n",
    "            for ind, pname in enumerate(out_links):\n",
    "                   #TODO: Create inlink dictionary by populating self.inlink_dict see the function description:\n",
    "                   #If a webpage is inlinked from more than one main pages then indeces are updated.\n",
    "                   #For example: Consider a entery in link_dict is  'usnews.com': [[10], [1], [44]], \n",
    "                   #Then, webpage usnews.com has index 10 and inlinked by main pages 1 and 44.\n",
    "            \n",
    "\n",
    "        def outlinkgraph(self, out_links):\n",
    "            \"\"\"Creates dictionary of out link graph that records out_links with pagename, pageindex and mainpageindex,\n",
    "                If a webpage has many out linkes then indeces are updated.\n",
    "                For example: Consider a entery in outlink_dict is  'abc.com': [[2], [5], [6]], \n",
    "                Then, webpage abc.com has index 2 and outlinked to  pages 5 and 6.\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                 out_links: list\n",
    "                    A processed list of all pages in a data file\n",
    "                \n",
    "            \"\"\"\n",
    "            for ind, pname in enumerate(out_links):\n",
    "                #TODO: Create outlink dictionary by populating self.outlink_dict see the function description:\n",
    "                #For example: Consider a entery in outlink_dict is  'abc.com': [[2], [5], [6]], \n",
    "                #Then, webpage abc.com has index 2 and outlinked to  pages 5 and 6.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc6dd076",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-4-6d2f19fa3f3f>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-6d2f19fa3f3f>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    def adjHITS(self, dict_outlinks):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class AdjacencyMatrices(PopulateDictionaries):\n",
    "    def __init__(self):\n",
    "        self.adj_m_pagerank=None #Initialise the adjacancey matrix for pagerank algo.\n",
    "        self.adj_m_HITS=None    #Initialise the adjacancey matrix for HITS algo.\n",
    "        PopulateDictionaries.__init__(self) \n",
    "    \n",
    "###############Create Adjacency matrix Page rank\n",
    "    def adjpagerank(self, dict_inlinks):\n",
    "        \"\"\"Adjacacy matrix for page rank algo:  \n",
    "                        #An Adjacency matrix of in links of web pages divided by total number of out links of a page.\n",
    "                        #Each element of A that is A_i,j  represents the out link from web page 'i' (row) to web page 'j' (column).\n",
    "                        #Alternatively,  We can also say that in link from web page 'j' (column) to web page 'i' (row).\n",
    "                        #Note that  for all 'i' sum(i, M_i,j) = 1 and A must be a square matrix.\n",
    "                        \n",
    "        Parameters\n",
    "        ----------\n",
    "       \n",
    "        dict_inlinks : dictionary\n",
    "               A dictionary of in links\n",
    "    \n",
    "    \n",
    "        \n",
    "        \"\"\"\n",
    "        zero_data = np.zeros(shape=(len(dict_inlinks),len(dict_inlinks)))\n",
    "        self.adj_m_pagerank = pd.DataFrame(zero_data)\n",
    "\n",
    "        for i in dict_inlinks:\n",
    "            #TODO:Populate self.adj_m_pagerank as per instructions in the assignment lecture and slides \n",
    "            \n",
    "\n",
    "###############Create Adjacency matrix FOR HITS\n",
    "    def adjHITS(self, dict_outlinks):\n",
    "        \"\"\"Adjacacy matrix for HITS algo:  \n",
    "                        #An Adjacency matrix of out links of web pages.\n",
    "                        #Each element of L that is L_i,j  represents the out link from web page 'i' (row) to web page 'j' (column).\n",
    "                        #Note L must be a square matrix.\n",
    "                        \n",
    "        Parameters\n",
    "        ----------\n",
    "       \n",
    "        dict_inlinks : dictionary\n",
    "               A dictionary of out links\n",
    "    \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        zero_data = np.zeros(shape=(len(dict_outlinks),len(dict_outlinks)))\n",
    "        self.adj_m_HITS = pd.DataFrame(zero_data)\n",
    "        for i in dict_outlinks:\n",
    "             #TODO:Populate self.adj_m_HITS as per instructions in the assignment lecture and slides \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e97ecf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PagerankAlgo():\n",
    "    def __init__(self, A, d):\n",
    "        self.d= d       #Teleporting parameter\n",
    "        \n",
    "        self.A= A       #An Adjacency matrix of in links of web pages divided by total number of out links of a page.\n",
    "                        #Each element of A that is A_i,j  represents the out link from web page 'i' (row) to web page 'j' (column).\n",
    "                        #Note that  for all 'i' sum(i, M_i,j) = 1 and A must be a square matrix.\n",
    "        \n",
    "        self.P= np.ones(len(self.A)) #Intial page rank =1\n",
    "\n",
    "\n",
    "    def calc_pagerank(self, max_itrs):\n",
    "        \n",
    "        \"\"\"PageRank Algorithm:  This algorithm was propsed by the Larry Page and Sergey Brin at Stanford University \n",
    "                            and it ranks the web pages by measuring their importance.\n",
    "                            It is used by the search engine Google.\n",
    "        Parameters\n",
    "        ----------\n",
    "       \n",
    "        max_itrs : int\n",
    "               Max number of iterations\n",
    "    \n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        numpy array\n",
    "            A vector of ranks such that p_i is the i-th rank in the range of [0, 1].\n",
    "    \n",
    "        Note\n",
    "        -----\n",
    "            1) Don't forget to normalize the page rank values in each iteration by max of page rank value.\n",
    "               This is done to restrict the page rank values in the range of 1-0.\n",
    "            2) Finally, normalize the page ranks by the sum of values of page ranks. This is only done at the \n",
    "               final calculation.\n",
    "               This is done to so that sum of final page ranks =1.\n",
    "        \"\"\"\n",
    "        #Check if A is square matrix\n",
    "        assert(self.A.shape[0]==self.A.shape[1])\n",
    "        page_ranks=None\n",
    "        #TODO: Implement PageRank algorithm according to assignment lecture and slides. \n",
    "        \n",
    "            \n",
    "        return(page_ranks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "03e264ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HITSalgo():\n",
    "    def __init__(self, L):\n",
    "        self.L= L   #An Adjacency matrix of out links of web pages \n",
    "                    #Each element of L that is L_i,j  represents the out link from web page 'i' to web page 'j'.\n",
    "                    #Note that L must be a square matrix.\n",
    "                    \n",
    "        self.a= np.ones(len(L)) #Initial authority values =1\n",
    "        self.h= np.ones(len(L)) #Initial hub values =1\n",
    "\n",
    "\n",
    "\n",
    "    def calc_HITS(self, max_itrs):\n",
    "        \"\"\"HITS Algorithm:  HITS algorithm was propsed by Jon M. Lleinberg  at Cornell University \n",
    "                            and it ranks the web pages by measuring their authoraty and hubs.\n",
    "                            It is used by the search engine Ask.\n",
    "        Parameters\n",
    "        ----------\n",
    "        max_itrs : int\n",
    "               Max number of iterations\n",
    "    \n",
    "   \n",
    "        Returns\n",
    "        -------\n",
    "        Panda series\n",
    "            A series conisting of normalized authority and  hub scores.\n",
    "    \n",
    "        Note\n",
    "        -----\n",
    "        1) Don't forget to normalize the authority score by the sum of sequare values of all authority score. \n",
    "        2) Don't forget to normalize the hub score by the sum of sequare values of all hub score.\n",
    "        \"\"\"\n",
    "       \n",
    "        #Check if adjacency matrix is a square matrix\n",
    "        assert(self.L.shape[0]==self.L.shape[1])\n",
    "        \n",
    "        a_cal=self.a\n",
    "        h_cal=self.h\n",
    "        \n",
    "        #TODO: Implement HITS algorithm according to assignment lecture and slides.\n",
    "        \n",
    "        return(a_cal, h_cal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "335c7eb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdjacencyMatrices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-13cede1487bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#MAIN of the code, #if __name__ == '__main__'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpp_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdjacencyMatrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Your file path'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/*.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdjacencyMatrices' is not defined"
     ]
    }
   ],
   "source": [
    "#MAIN of the code, #if __name__ == '__main__'\n",
    "pp_data = AdjacencyMatrices()\n",
    "\n",
    "file_list =  glob.glob('Your file path' + \"/*.csv\")\n",
    "\n",
    "for fl in file_list:\n",
    "   \n",
    "    pp_data.removeselflinks(fl)\n",
    "    list_out_links= pp_data.unique_processed_links.tolist()\n",
    "    pp_data.addpages(list_out_links)\n",
    "    pp_data.inlinkgraph(list_out_links)\n",
    "    pp_data.outlinkgraph(list_out_links)\n",
    "    \n",
    "print(pp_data.pages)\n",
    "print('In Links: \\n', pp_data.inlink_dict)\n",
    "print('Out Links:\\n', pp_data.outlink_dict ) \n",
    "print(' \\n')\n",
    "\n",
    "#AdjacencyMatrices\n",
    "##.  PageRank\n",
    "pp_data.adjpagerank(pp_data.inlink_dict)\n",
    "print(\"PageRankAdjMatr \\n\", pp_data.adj_m_pagerank )\n",
    "print( 'If the rows are summing up to one in  adj_m_pagerank:\\n',pp_data.adj_m_pagerank.sum(axis=1)[0:25])\n",
    "print( 'Number of in-links in adj_m_pagerank: \\n',np.count_nonzero(pp_data.adj_m_pagerank, axis=0)[0:25])\n",
    "print( 'Number of out-links in adj_m_pagerank: \\n',np.count_nonzero(pp_data.adj_m_pagerank, axis=1)[0:25])\n",
    "\n",
    "##. HITS\n",
    "pp_data.adjHITS(pp_data.outlink_dict)\n",
    "print(\"HITSAdjMatr \\n\", pp_data.adj_m_HITS )\n",
    "# Number of outlinks in adj_m_HITS\n",
    "print( 'Number of outlinks in adj_m_HITS:\\n',pp_data.adj_m_HITS.sum(axis=1)[0:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e75ff2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PagerankAlgo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7293eeaf60ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mPagerankAlgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_m_pagerank\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpage_rank_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_pagerank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Highest page rank score is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage_rank_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Page rank scores:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_rank_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PagerankAlgo' is not defined"
     ]
    }
   ],
   "source": [
    "pr= PagerankAlgo(pp_data.adj_m_pagerank , 0.85)\n",
    "page_rank_score=pr.calc_pagerank(50)\n",
    "print('Highest page rank score is:', max(page_rank_score))\n",
    "print('Page rank scores:\\n', page_rank_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ca0d45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HITSalgo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5b3ecd63836c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mHITSalgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpp_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj_m_HITS\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mHITS_scores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_HITS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Highest authority score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mHITS_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Authority scores:\\n'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mHITS_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HITSalgo' is not defined"
     ]
    }
   ],
   "source": [
    "hr= HITSalgo(pp_data.adj_m_HITS )\n",
    "HITS_scores=hr.calc_HITS(5)\n",
    "print('Highest authority score:', max( HITS_scores[0] ))\n",
    "print('Authority scores:\\n',  HITS_scores[0] )\n",
    "\n",
    "print('Highest hub:', max( HITS_scores[1]))\n",
    "print('Hub scores:\\n',  HITS_scores[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261c092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
